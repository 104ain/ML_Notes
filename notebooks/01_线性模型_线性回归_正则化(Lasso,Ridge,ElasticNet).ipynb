{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.过拟合\n",
    "建模的目的是让模型学习到数据的一般性规律，但如果模型太复杂，反而容易学过头，学到一些数据的噪声特性，虽然模型在训练集上表现很好，但在测试集上结果往往会变差，这时模型陷入了**过拟合**，接下来造一些伪数据进行演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成200条数据，前100条数据做训练，后100条数据做测试\n",
    "X=np.random.random(size=(200,20))\n",
    "tw=np.random.random(size=(20,1))*100#设置w\n",
    "tb=np.random.random()#设置b\n",
    "Y=X.dot(tw)+tb\n",
    "X=X+np.random.random(size=(200,20))*0.5#给X加噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_models.linear_model import *\n",
    "lr=LinearRegression()\n",
    "lr.fit(X[:100],Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 38.92647827774521, '测试集std:', 43.58590001127093)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看训练集，测试集上的误差\n",
    "'训练集std:',np.std(Y[:100]-lr.predict(X[:100])),'测试集std:',np.std(Y[100:]-lr.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.正则化\n",
    "可以看到，测试集上误差比训练集的误差高出不少，避免模型陷入过拟合，通常可以通过正则化技术避免，常见的操作就是在loss函数中为权重$w$添加$L_1$或者$L_2$约束，借用上一节的公式推导，直接展示loss部分：  \n",
    "\n",
    "1.线性回归中添加$L_1$约束称为Lasso回归，其损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\lambda||w||_1\n",
    "$$  \n",
    "2.线性回归中添加$L_2$约束称为Ridge回归，其损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\alpha||w||_2\n",
    "$$ \n",
    "3.如果不太确定用$L_1$好，还是$L_2$好，可以用它们的组合，称作ElasticNet，损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\lambda||w||_1+\\alpha||w||_2\n",
    "$$ \n",
    "可以发现通过调整超参，可以控制$w$的大小，如果$\\lambda$或$\\alpha$设置很大，$w$会被约束的很小，而如果$\\alpha$或$\\lambda$设置为0，等价于原始的不带正则项的线性回归；通常可以通过交叉验证，根据验证集上的表现来设置一个合适的超参；接下来在上一节线性回归代码的基础上实现Lasso,Ridge,ElasticNet模型，另外设置两个参数`l1_ratio`以及`l2_ratio`，分别用来控制$L_1$和$L_2$的loss部分的权重\n",
    "### 三.代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, fit_intercept=True, solver='sgd', if_standard=True, epochs=10, eta=1e-2, batch_size=1,\n",
    "                 l1_ratio=None, l2_ratio=None):\n",
    "        \"\"\"\n",
    "        :param fit_intercept: 是否训练bias\n",
    "        :param solver:\n",
    "        :param if_standard:\n",
    "        \"\"\"\n",
    "        self.w = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.solver = solver\n",
    "        self.if_standard = if_standard\n",
    "        if if_standard:\n",
    "            self.feature_mean = None\n",
    "            self.feature_std = None\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.l2_ratio = l2_ratio\n",
    "        # 注册sign函数\n",
    "        self.sign_func = np.vectorize(utils.sign)\n",
    "\n",
    "    def init_params(self, n_features):\n",
    "        \"\"\"\n",
    "        初始化参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.w = np.random.random(size=(n_features, 1))\n",
    "\n",
    "    def _fit_closed_form_solution(self, x, y):\n",
    "        \"\"\"\n",
    "        直接求闭式解\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.l1_ratio is None and self.l2_ratio is None:\n",
    "            self.w = np.linalg.pinv(x).dot(y)\n",
    "        elif self.l1_ratio is None and self.l2_ratio is not None:\n",
    "            self.w = np.linalg.inv(x.T.dot(x) + self.l2_ratio * np.eye(x.shape[1])).dot(x.T).dot(y)\n",
    "        else:\n",
    "            self._fit_sgd(x, y)\n",
    "\n",
    "    def _fit_sgd(self, x, y):\n",
    "        \"\"\"\n",
    "        随机梯度下降求解\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :param epochs:\n",
    "        :param eta:\n",
    "        :param batch_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_y = np.c_[x, y]\n",
    "        # 按batch_size更新w,b\n",
    "        for _ in range(self.epochs):\n",
    "            np.random.shuffle(x_y)\n",
    "            for index in range(x_y.shape[0] // self.batch_size):\n",
    "                batch_x_y = x_y[self.batch_size * index:self.batch_size * (index + 1)]\n",
    "                batch_x = batch_x_y[:, :-1]\n",
    "                batch_y = batch_x_y[:, -1:]\n",
    "\n",
    "                dw = -2 * batch_x.T.dot(batch_y - batch_x.dot(self.w)) / self.batch_size\n",
    "\n",
    "                # 添加l1和l2的部分\n",
    "                dw_reg = np.zeros(shape=(x.shape[1] - 1, 1))\n",
    "                if self.l1_ratio is not None:\n",
    "                    dw_reg += self.l1_ratio * self.sign_func(self.w[:-1]) / self.batch_size\n",
    "                if self.l2_ratio is not None:\n",
    "                    dw_reg += 2 * self.l2_ratio * self.w[:-1] / self.batch_size\n",
    "                dw_reg = np.concatenate([dw_reg, np.asarray([[0]])], axis=0)\n",
    "                dw += dw_reg\n",
    "                self.w = self.w - self.eta * dw\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # 是否归一化feature\n",
    "        if self.if_standard:\n",
    "            self.feature_mean = np.mean(x, axis=0)\n",
    "            self.feature_std = np.std(x, axis=0) + 1e-8\n",
    "            x = (x - self.feature_mean) / self.feature_std\n",
    "        # 是否训练bias\n",
    "        if self.fit_intercept:\n",
    "            x = np.c_[x, np.ones_like(y)]\n",
    "        # 初始化参数\n",
    "        self.init_params(x.shape[1])\n",
    "        # 训练模型\n",
    "        if self.solver == 'closed_form':\n",
    "            self._fit_closed_form_solution(x, y)\n",
    "        elif self.solver == 'sgd':\n",
    "            self._fit_sgd(x, y)\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        输出原始的系数\n",
    "        :return: w,b\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            w = self.w[:-1]\n",
    "            b = self.w[-1]\n",
    "        else:\n",
    "            w = self.w\n",
    "            b = 0\n",
    "        if self.if_standard:\n",
    "            w = w / self.feature_std.reshape(-1, 1)\n",
    "            b = b - w.T.dot(self.feature_mean.reshape(-1, 1))\n",
    "        return w.reshape(-1), b\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x:ndarray格式数据: m x n\n",
    "        :return: m x 1\n",
    "        \"\"\"\n",
    "        if self.if_standard:\n",
    "            x = (x - self.feature_mean) / self.feature_std\n",
    "        if self.fit_intercept:\n",
    "            x = np.c_[x, np.ones(shape=x.shape[0])]\n",
    "        return x.dot(self.w)\n",
    "\n",
    "    def plot_fit_boundary(self, x, y):\n",
    "        \"\"\"\n",
    "        绘制拟合结果\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        plt.scatter(x[:, 0], y)\n",
    "        plt.plot(x[:, 0], self.predict(x), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 39.739679305872265, '测试集std:', 45.36042539946315)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=LinearRegression(l1_ratio=0.01)\n",
    "lasso.fit(X[:100],Y[:100])\n",
    "#查看训练集，测试集上的误差\n",
    "'训练集std:',np.std(Y[:100]-lasso.predict(X[:100])),'测试集std:',np.std(Y[100:]-lasso.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 118.61397787324181, '测试集std:', 101.62672135934089)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#与sklearn对比\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso()\n",
    "lasso.fit(X[:100],Y[:100])\n",
    "'训练集std:',np.std(Y[:100]-lasso.predict(X[:100])),'测试集std:',np.std(Y[100:]-lasso.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 38.51364038546339, '测试集std:', 42.68319768869535)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge=LinearRegression(l2_ratio=0.01)\n",
    "ridge.fit(X[:100],Y[:100])\n",
    "#查看训练集，测试集上的误差 \n",
    "'训练集std:',np.std(Y[:100]-ridge.predict(X[:100])),'测试集std:',np.std(Y[100:]-ridge.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 37.19078218147727, '测试集std:', 42.53910405375569)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#与sklearn对比\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge=Ridge()\n",
    "ridge.fit(X[:100],Y[:100])\n",
    "'训练集std:',np.std(Y[:100]-ridge.predict(X[:100])),'测试集std:',np.std(Y[100:]-ridge.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 37.39721822175668, '测试集std:', 43.91945143391026)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic=LinearRegression(l1_ratio=0.01,l2_ratio=0.01)\n",
    "elastic.fit(X[:100],Y[:100])\n",
    "#查看训练集，测试集上的误差\n",
    "'训练集std:',np.std(Y[:100]-elastic.predict(X[:100])),'测试集std:',np.std(Y[100:]-elastic.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('训练集std:', 94.67535553651277, '测试集std:', 82.85456858410238)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#与sklearn对比\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic=ElasticNet()\n",
    "elastic.fit(X[:100],Y[:100])\n",
    "'训练集std:',np.std(Y[:100]-elastic.predict(X[:100])),'测试集std:',np.std(Y[100:]-elastic.predict(X[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将sign函数整理到ml_models.utils中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
